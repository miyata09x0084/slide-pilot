"""
PDFÂá¶ÁêÜ„ÉÑ„Éº„É´ (Issue #17, #29)
PDF„Éï„Ç°„Ç§„É´„Åã„Çâ„ÉÜ„Ç≠„Çπ„Éà„ÇíÊäΩÂá∫„Åó„Å¶„ÄÅ„Çπ„É©„Ç§„ÉâÁîüÊàê„Å´ÈÅ©„Åó„ÅüÂΩ¢Âºè„Å´Â§âÊèõ

Issue #29: Supabase StorageÂØæÂøú
"""

from langchain_core.tools import tool
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from pathlib import Path
import json
import tempfile
from typing import Dict, Any
from app.core.storage import download_from_storage


@tool
def process_pdf(file_path: str) -> str:
    """
    PDF„Éï„Ç°„Ç§„É´„Åã„Çâ„ÉÜ„Ç≠„Çπ„Éà„ÇíÊäΩÂá∫„Åó„Å¶Ë¶ÅÁ¥ÑÂèØËÉΩ„Å™ÂΩ¢Âºè„Å´Â§âÊèõ

    Supabase Storage„Éë„Çπ or „É≠„Éº„Ç´„É´„Éë„Çπ„Å´ÂØæÂøú

    Args:
        file_path: PDF„Éï„Ç°„Ç§„É´„ÅÆ„Éë„ÇπÔºàStorage„Éë„Çπ: user_id/filename.pdf or „É≠„Éº„Ç´„É´„Éë„ÇπÔºâ

    Returns:
        JSONÊñáÂ≠óÂàó: {
            "status": "success" | "error",
            "content": str (ÊäΩÂá∫„Åï„Çå„Åü„ÉÜ„Ç≠„Çπ„Éà),
            "num_pages": int („Éö„Éº„Ç∏Êï∞),
            "total_chars": int (Á∑èÊñáÂ≠óÊï∞),
            "message": str („Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÄÅ„Ç®„É©„ÉºÊôÇ„ÅÆ„Åø)
        }
    """
    temp_file = None
    try:
        # Supabase Storage„Éë„Çπ„ÅÆÂ†¥ÂêàÔºàuser_id/filename.pdf„ÅÆÂΩ¢ÂºèÔºâ
        if '/' in file_path and not file_path.startswith('/'):
            # Supabase Storage„Åã„Çâ„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÔºàË§áÊï∞user_id„ÇíË©¶Ë°åÔºâ
            pdf_data = download_from_storage(bucket="uploads", file_path=file_path)

            # ÊåáÂÆö„Åï„Çå„Åü„Éë„Çπ„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÂ§±Êïó„Åó„ÅüÂ†¥Âêà„ÄÅanonymous/„ÇÇË©¶„Åô
            if not pdf_data and not file_path.startswith("anonymous/"):
                # „Éï„Ç°„Ç§„É´Âêç„ÅÆ„Åø„ÇíÊäΩÂá∫
                filename = file_path.split('/')[-1]
                fallback_path = f"anonymous/{filename}"
                print(f"[process_pdf] Trying fallback path: {fallback_path}")
                pdf_data = download_from_storage(bucket="uploads", file_path=fallback_path)

            if not pdf_data:
                return json.dumps({
                    "status": "error",
                    "message": f"Supabase Storage„Åã„Çâ„Éï„Ç°„Ç§„É´„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åß„Åç„Åæ„Åõ„Çì: {file_path}"
                }, ensure_ascii=False)

            # ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò
            temp_file = tempfile.NamedTemporaryFile(suffix=".pdf", delete=False)
            temp_file.write(pdf_data)
            temp_file.close()
            pdf_path = Path(temp_file.name)
        else:
            # „É≠„Éº„Ç´„É´„Éë„Çπ„ÅÆÂ†¥Âêà
            pdf_path = Path(file_path)
            if not pdf_path.exists():
                return json.dumps({
                    "status": "error",
                    "message": f"„Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: {file_path}"
                }, ensure_ascii=False)

        if not pdf_path.suffix.lower() == '.pdf':
            return json.dumps({
                "status": "error",
                "message": "PDF„Éï„Ç°„Ç§„É´„Åß„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì"
            }, ensure_ascii=False)

        # PDF„Åã„Çâ„ÉÜ„Ç≠„Çπ„ÉàÊäΩÂá∫
        loader = PyPDFLoader(str(pdf_path))
        pages = loader.load()

        if not pages:
            return json.dumps({
                "status": "error",
                "message": "PDF„Åã„Çâ„ÉÜ„Ç≠„Çπ„Éà„ÇíÊäΩÂá∫„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü"
            }, ensure_ascii=False)

        # ÂÖ®„Éö„Éº„Ç∏„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„ÇíÁµêÂêà
        full_text = "\n\n".join([page.page_content for page in pages])

        if not full_text.strip():
            return json.dumps({
                "status": "error",
                "message": "PDF„Å´„ÉÜ„Ç≠„Çπ„Éà„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„Åæ„Åõ„ÇìÔºàÁîªÂÉè„ÅÆ„Åø„ÅÆPDF„ÅÆÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„ÅôÔºâ"
            }, ensure_ascii=False)

        # Èï∑Êñá„ÇíÈÅ©Âàá„Å™„Çµ„Ç§„Ç∫„Å´ÂàÜÂâ≤ÔºàLLM„ÅÆ„Ç≥„É≥„ÉÜ„Ç≠„Çπ„ÉàÂà∂ÈôêÂØæÁ≠ñÔºâ
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=4000,
            chunk_overlap=200,
            separators=["\n\n", "\n", "„ÄÇ", ".", " ", ""]
        )
        chunks = splitter.split_text(full_text)

        # „ÉÅ„É£„É≥„ÇØ„ÇíÁµêÂêàÔºà„Çπ„É©„Ç§„ÉâÁîüÊàê„Å´‰Ωø„ÅÑ„ÇÑ„Åô„ÅÑÂΩ¢ÂºèÔºâ
        processed_content = "\n\n---\n\n".join(chunks)

        return json.dumps({
            "status": "success",
            "content": processed_content,
            "num_pages": len(pages),
            "total_chars": len(full_text),
            "num_chunks": len(chunks)
        }, ensure_ascii=False)

    except Exception as e:
        return json.dumps({
            "status": "error",
            "message": f"PDFÂá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {str(e)}"
        }, ensure_ascii=False)
    finally:
        # ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´„ÇíÂâäÈô§
        if temp_file and Path(temp_file.name).exists():
            Path(temp_file.name).unlink()


def test_pdf_processor(pdf_path: str) -> None:
    """PDFÂá¶ÁêÜ„ÉÑ„Éº„É´„ÅÆ„ÉÜ„Çπ„ÉàÁî®Èñ¢Êï∞"""
    print(f"üìÑ Testing PDF processor with: {pdf_path}")
    result = process_pdf(pdf_path)
    data = json.loads(result)

    if data["status"] == "success":
        print("‚úÖ PDFÂá¶ÁêÜÊàêÂäü")
        print(f"   „Éö„Éº„Ç∏Êï∞: {data['num_pages']}")
        print(f"   Á∑èÊñáÂ≠óÊï∞: {data['total_chars']}")
        print(f"   „ÉÅ„É£„É≥„ÇØÊï∞: {data['num_chunks']}")
        print(f"   ÊäΩÂá∫„ÉÜ„Ç≠„Çπ„ÉàÔºàÂÖàÈ†≠200ÊñáÂ≠óÔºâ:")
        print(f"   {data['content'][:200]}...")
    else:
        print(f"‚ùå PDFÂá¶ÁêÜÂ§±Êïó: {data['message']}")


if __name__ == "__main__":
    # „ÉÜ„Çπ„ÉàÂÆüË°å
    import sys

    if len(sys.argv) > 1:
        test_pdf_processor(sys.argv[1])
    else:
        print("‰Ωø„ÅÑÊñπ: python pdf_processor.py <PDF_FILE_PATH>")
