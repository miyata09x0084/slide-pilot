# LangGraph Ã— LangSmith Ã— OpenAI Ã— Tavily Ã— Marp
# ãƒ•ãƒ­ãƒ¼:
# 0) Tavilyã§æƒ…å ±åé›† -> 1) ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ç”Ÿæˆ -> 2) ç›®æ¬¡ç”Ÿæˆ -> 3) ã‚¹ãƒ©ã‚¤ãƒ‰(Marp)æœ¬æ–‡ç”Ÿæˆ -> 4) è©•ä¾¡(>=8ã§OK/ãã‚Œä»¥å¤–ã¯2ã¸ãƒ«ãƒ¼ãƒ—) -> 5) ã‚¹ãƒ©ã‚¤ãƒ‰Markdownä¿å­˜(+ marp-cliã§pdf/png/htmlå‡ºåŠ›)

from zoneinfo import ZoneInfo
from dotenv import load_dotenv
from typing import Optional, Dict, Any, Union
from typing_extensions import TypedDict
import os
import re
import requests
from typing import List
from datetime import datetime, timedelta, timezone
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_core.runnables import RunnableConfig
from langsmith import traceable
from langgraph.graph import StateGraph, START, END
import json
from pathlib import Path
import shutil
import subprocess

# -------------------
# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
# -------------------

load_dotenv()

def _get_env(key: str, default: Optional[str] = None) -> str:
  value = os.getenv(key)
  if value is None:
    raise ValueError(f"missing environment variable: {key}")
  return value

# LangSmith
os.environ.setdefault("LANGCHAIN_TRACING_V2", "true")
os.environ.setdefault("LANGCHAIN_ENDPOINT", "https://api.smith.langchain.com")

# OpenAI API
# API ã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‹ã‚‰è‡ªå‹•èª­ã¿è¾¼ã¿
# æ˜ç¤ºçš„ã«èª­ã¿è¾¼ã‚€å ´åˆã®ã¿ä»¥ä¸‹ã‚’ä½¿ç”¨
# OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Tavily
TAVILY_API_KEY = _get_env("TAVILY_API_KEY")

# Marp å‡ºåŠ›ï¼ˆPDF/PNG/HTMLï¼‰ã€‚ç©ºãªã‚‰ .md ã«å‡ºåŠ›
SLIDE_FORMAT = os.getenv("SLIDE_FORMAT", "").lower().strip()
MARP_THEME = os.getenv("MARP_THEME", "default") # default/gaia/gaia-dark/gaia-light
MARP_PAGINATE = os.getenv("MARP_PAGINATE", "true") # true/false

# -------------------
# LLM ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
# -------------------
llm = ChatOpenAI(
  model="gpt-4o",  # æœ€æ–°ã®GPT-4 Omniãƒ¢ãƒ‡ãƒ«ï¼ˆã¾ãŸã¯ "gpt-3.5-turbo" ã§ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‰
  temperature=0.2,
  max_retries=2,    # ãƒªãƒˆãƒ©ã‚¤å›æ•°
  # api_key ã¯ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‹ã‚‰è‡ªå‹•èª­ã¿è¾¼ã¿
)

# -------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -------------------
def _log(state: dict, msg: str) -> List[str]:
    return (state.get("logs") or []) + [msg]

def _strip_bullets(lines: List[str]) -> List[str]:
    """ç®‡æ¡æ›¸ãã‹ã‚‰ä¸è¦ãªè¨˜å·ã‚’é™¤å»"""
    output = []
    for line in lines:
      t = line.strip()
      if not t:
        continue
      t = t.lstrip("ãƒ»-â€¢* \t")
      output.append(t)
    return output

def _slugify_en(text: str, max_length: int = 80) -> str:
    text = (text or "").lower()
    text = re.sub(r"[^a-z0-9]+", "-", text)
    text = re.sub(r"-+", "-", text).strip("-")
    return text[:max_length] or "slide"

def _find_json(text: str) -> Optional[str]:
    t = text.strip()
    t = re.sub(r"^```(?:json)?\s*", "", t)
    t = re.sub(r"\s*```$", "", t)
    m = re.search(r"\{.*\}\s*$", t, flags=re.DOTALL)
    if m:
      return m.group(0)
    return None

def _ensure_marp_header(md: str, title: str) -> str:
    """
    Markdownã«Marpç”¨ã®YAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰è¨­å®šã®ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†ï¼‰ã‚’è¨­å®šã™ã‚‹ã€‚
    æ—¢å­˜ã®ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã¯å‰Šé™¤ã—ã€æ–°ã—ã„ãƒ†ãƒ¼ãƒãƒ»ãƒšãƒ¼ã‚¸ç•ªå·è¨­å®šç­‰ã§ç½®ãæ›ãˆã‚‹ã€‚
    """
    # Marpç”¨YAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’æ§‹ç¯‰
    header = (
      "---\n"
          "marp: true\n"                    # Marpå‡¦ç†ã‚’æœ‰åŠ¹åŒ–
          f"paginate: {MARP_PAGINATE}\n"     # ãƒšãƒ¼ã‚¸ç•ªå·è¡¨ç¤ºè¨­å®š
          f"theme: {MARP_THEME}\n"           # ãƒ†ãƒ¼ãƒè¨­å®š
          f"title: {title}\n"                # ã‚¹ãƒ©ã‚¤ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«
          "---\n\n"
    )

    # æ—¢å­˜ã®ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ï¼ˆ---...---ï¼‰ã‚’å‰Šé™¤ã—ã¦æœ¬æ–‡ã®ã¿æŠ½å‡º
    body = re.sub(r"^---[\s\S]*?---\s*", "", md.strip(), count=1, flags=re.DOTALL)

    # æ–°ãƒ˜ãƒƒãƒ€ãƒ¼ + æœ¬æ–‡ã‚’çµåˆï¼ˆæœ«å°¾æ”¹è¡Œã‚’ä¿è¨¼ï¼‰
    return header + (body + ("\n" if not body.endswith("\n") else ""))

def _insert_separators(md: str) -> str:
    """
    ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’å£Šã•ãšã€H2(## )ã®ç›´å‰ã«1ã¤ã ã‘ '---' ã‚’å…¥ã‚Œã‚‹ã€‚
    """
    if not md or md is None:
        return ""

    out = [] # å‡ºåŠ›ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    in_code = False # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã‹ã©ã†ã‹
    fence = None # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®é–‹å§‹ãƒãƒ¼ã‚«ãƒ¼ (``` or ~~~)
    prev = "" # ç›´å‰ã®è¡Œ

    def need_sep(prev_line: str) -> bool:
      pl = prev_line.strip()
      # ç›´å‰ãŒã™ã§ã« --- ãªã‚‰ä¸è¦
      return pl != "---"

    for line in md.splitlines():
      # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®æ¤œå‡º
      if line.startswith("```") or line.startswith("~~~"):
        if not in_code:
          in_code, fence = True, line[:3]
        else:
          if fence and line.startswith(fence):
            in_code, fence = False, None
          out.append(line)
          prev = line
          continue

      # H2(## )ã®ç›´å‰ã«1ã¤ã ã‘ '---' ã‚’å…¥ã‚Œã‚‹
      if not in_code and line.startswith("## "):
        if need_sep(prev): # å‰ã®è¡ŒãŒ"---"ã§ãªã‘ã‚Œã°
          out.append("---") # ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿æŒ¿å…¥
        out.append(line)
      else:
        out.append(line)
      prev = line

    return "\n".join(out).strip() + "\n"

def _double_separators(md: str) -> str:
    """
    é€£ç¶šã™ã‚‹åŒºåˆ‡ã‚Šï¼ˆ---, ç©ºè¡Œ, --- ...) ã‚’1å€‹ã«åœ§ç¸®ã€‚
    """
    if not md or md is None:
        return ""

    # --- ã®é€£ç¶šã‚„ã€--- ã®é–“ã®ç©ºè¡Œã‚’æ½°ã™
    md = re.sub(r"(?:\n*\s*---\s*\n+){2,}", "\n---\n", md)
    # å…ˆé ­ã®ä½™åˆ†ãª --- ã‚’1å€‹ã«
    md = re.sub(r"^(?:\s*---\s*\n)+", "---\n", md)
    return md


# JSTã®ç¾åœ¨æ—¥æ™‚ã‚’å–å¾—
JST = ZoneInfo("Asia/Tokyo")

def now_jst() -> str:
  return datetime.now(JST)

def today_iso(fmt: str = "%Y-%m-%d") -> str:
  return now_jst().strftime(fmt)

def month_ja() -> str:
  dt = now_jst()
  # Windowsã§ã‚‚å‹•ãã‚ˆã†ã« %-m ã‚’ä½¿ã‚ãšã€0åŸ‹ã‚ã‚‚ã—ãªã„
  return f"{dt.year}å¹´{dt.month}æœˆ"

def month_en() -> str:
  months = ["January","February","March","April","May","June",
              "July","August","September","October","November","December"]
  dt = now_jst()
  return f"{months[dt.month-1]} {dt.year}"

@tool("get_today_jst", return_direct=True)
def get_today_jst(fmt: str = "%Y-%m-%d") -> str:
  """JSTã§ä»Šæ—¥ã®æ—¥ä»˜ã‚’è¿”ã™ï¼ˆä¾‹: %Y-%m-%d, %Yå¹´%mæœˆ ãªã©ï¼‰"""
  return datetime.now(JST).strftime(fmt)

def _clean_title(raw: str) -> str:
  t = (raw or "").strip().splitlines()[0]
  t = t.strip("ã€Œã€ã€ã€\"' ã€€:ï¼š")
  t = re.sub(r"^(ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¿ã‚¤ãƒˆãƒ«.*|title:?|suggested:?|æ¡ˆ:?)[\sï¼š:]*", "", t, flags=re.IGNORECASE)
  return t or "[æœ¬æ—¥ã®æ—¥ä»˜] AIæœ€æ–°æƒ…å ±ã¾ã¨ã‚"

def _strip_whole_code_fence(md: str) -> str:
  t = md.strip()
  if t.startswith("```"):
    t = re.sub(r"^```[a-zA-Z0-9_-]*\s*\n?", "", t)
    t = re.sub(r"\n?```$", "", t.strip())
  return t

def _remove_presenter_lines(md: str) -> str:
  """ã‚¿ã‚¤ãƒˆãƒ«ã‚¹ãƒ©ã‚¤ãƒ‰ï¼ˆå…ˆé ­ï½æœ€åˆã®'---'ã¾ã§ï¼‰ã‹ã‚‰ç™ºè¡¨è€…è¡Œã‚’é™¤å»"""
  if not md or md is None:
    return ""

  parts = md.split("\n---\n", 1)
  head = parts[0]
  head = re.sub(r"^\s*(ç™ºè¡¨è€…|Presenter|Speaker)\s*[:ï¼š].*$", "", head, flags=re.MULTILINE)
  head = re.sub(r"\n{3,}", "\n\n", head).strip() + "\n"
  return head + ("\n---\n" + parts[1] if len(parts) == 2 else "")

# -------------------
# Slidevç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (Phase 1 - MVP-4)
# -------------------
def _get_all_vendors_info() -> List[Dict]:
  """å…¨6ç¤¾ã®ãƒ™ãƒ³ãƒ€ãƒ¼æƒ…å ±ã‚’è¿”ã™ï¼ˆSlidevç”¨ï¼‰"""
  return [
    {
      "name": "Microsoft AI",
      "emoji": "ğŸ¢",
      "domains": ["azure.microsoft.com", "news.microsoft.com", "learn.microsoft.com"],
      "queries": ["Microsoft AI updates", "Azure OpenAI updates"],
      "gradient": "linear-gradient(135deg, #0078d4 0%, #00bcf2 100%)",
    },
    {
      "name": "OpenAI",
      "emoji": "ğŸ¤–",
      "domains": ["openai.com"],
      "queries": ["OpenAI announcements", "OpenAI updates"],
      "gradient": "linear-gradient(135deg, #10a37f 0%, #1a7f64 100%)",
    },
    {
      "name": "Google Gemini",
      "emoji": "ğŸŒŸ",
      "domains": ["blog.google", "ai.googleblog.com", "research.google"],
      "queries": ["Google AI updates", "Gemini updates"],
      "gradient": "linear-gradient(135deg, #4285f4 0%, #34a853 100%)",
    },
    {
      "name": "AWS Bedrock",
      "emoji": "â˜ï¸",
      "domains": ["aws.amazon.com"],
      "queries": ["AWS Bedrock updates", "Amazon AI updates"],
      "gradient": "linear-gradient(135deg, #ff9900 0%, #f90 100%)",
    },
    {
      "name": "Meta AI",
      "emoji": "ğŸ¦™",
      "domains": ["ai.meta.com"],
      "queries": ["Meta AI updates", "Llama updates"],
      "gradient": "linear-gradient(135deg, #0668e1 0%, #0a7cff 100%)",
    },
    {
      "name": "Anthropic",
      "emoji": "ğŸ§ ",
      "domains": ["anthropic.com"],
      "queries": ["Anthropic Claude updates", "Claude announcements"],
      "gradient": "linear-gradient(135deg, #d4a574 0%, #c49a6c 100%)",
    },
  ]

def _create_llm_summarized_bullets(results: List[Dict], vendor_name: str = "Microsoft AI", num_bullets: int = 3) -> List[str]:
  """æ¤œç´¢çµæœã‚’LLMã§è¦ç´„ã—ã¦ç®‡æ¡æ›¸ãã‚’ç”Ÿæˆï¼ˆSlidevç”¨ï¼‰

  Args:
    results: Tavilyæ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ
    vendor_name: ãƒ™ãƒ³ãƒ€ãƒ¼å
    num_bullets: ç”Ÿæˆã™ã‚‹ç®‡æ¡æ›¸ãã®æ•°

  Returns:
    ç®‡æ¡æ›¸ãã®ãƒªã‚¹ãƒˆ
  """
  # æ¤œç´¢çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã«æ•´å½¢
  results_text = ""
  for i, result in enumerate(results[:5], 1):
    title = result.get("title", "")
    content = result.get("content", "")[:300]
    url = result.get("url", "")
    results_text += f"\n### è¨˜äº‹ {i}\n"
    results_text += f"ã‚¿ã‚¤ãƒˆãƒ«: {title}\n"
    results_text += f"å†…å®¹: {content}\n"
    results_text += f"URL: {url}\n"

  if not results_text.strip():
    return [
      "- **æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ**",
      "- å¾Œã§ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„"
    ]

  # LLMã§ç®‡æ¡æ›¸ãã«è¦ç´„
  prompt = [
    ("system", "ã‚ãªãŸã¯AIæŠ€è¡“ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚æ¤œç´¢çµæœã‹ã‚‰é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡ºã—ã¾ã™ã€‚"),
    ("user",
     f"ä»¥ä¸‹ã®{vendor_name}ã«é–¢ã™ã‚‹æ¤œç´¢çµæœã‹ã‚‰ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’{num_bullets}ã¤ã®ç®‡æ¡æ›¸ãã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
     f"å„ç®‡æ¡æ›¸ãã¯1-2æ–‡ã§ã€æŠ€è¡“çš„ã«æ­£ç¢ºã‹ã¤åˆ†ã‹ã‚Šã‚„ã™ãè¨˜è¿°ã—ã¦ãã ã•ã„ã€‚\n\n"
     f"{results_text}\n\n"
     f"å‡ºåŠ›å½¢å¼:\n" + "\n".join([f"- ãƒã‚¤ãƒ³ãƒˆ{i+1}" for i in range(num_bullets)]))
  ]

  try:
    msg = llm.invoke(prompt)
    lines = msg.content.strip().split("\n")
    bullets = [line.strip() for line in lines if line.strip().startswith("-")][:num_bullets]

    # æŒ‡å®šæ•°ã«æº€ãŸãªã„å ´åˆã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    while len(bullets) < num_bullets:
      bullets.append("- ï¼ˆæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼‰")

    return bullets

  except Exception as e:
    # LLMå¤±æ•—æ™‚ã¯ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    fallback = []
    for result in results[:num_bullets]:
      title = result.get("title", "")[:80]
      if title:
        fallback.append(f"- **{title}**")

    while len(fallback) < num_bullets:
      fallback.append("- ï¼ˆæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼‰")

    return fallback[:num_bullets]

def _generate_multi_vendor_slides_integrated(topic: str, sources: Dict[str, List[Dict]], mvp_version: str = "AI Industry Report") -> str:
  """å…¨ãƒ™ãƒ³ãƒ€ãƒ¼ã®Slidevãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’ç”Ÿæˆï¼ˆmarp_agentçµ±åˆç‰ˆï¼‰

  Args:
    topic: ã‚¹ãƒ©ã‚¤ãƒ‰ã®ãƒˆãƒ”ãƒƒã‚¯
    sources: collect_info()ã§å–å¾—ã—ãŸTavilyæ¤œç´¢çµæœ
    mvp_version: ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¡¨è¨˜

  Returns:
    Slidevãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³æ–‡å­—åˆ—
  """
  vendors = _get_all_vendors_info()
  vendor_bullets = []

  # å„ãƒ™ãƒ³ãƒ€ãƒ¼ã®æ¤œç´¢çµæœã‹ã‚‰ç®‡æ¡æ›¸ãã‚’ç”Ÿæˆ
  for vendor in vendors:
    # sourcesã‹ã‚‰è©²å½“ã™ã‚‹ãƒ™ãƒ³ãƒ€ãƒ¼ã®æ¤œç´¢çµæœã‚’æŠ½å‡º
    vendor_results = []
    for query, items in sources.items():
      # ã‚¯ã‚¨ãƒªã«è©²å½“ã™ã‚‹ãƒ™ãƒ³ãƒ€ãƒ¼ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
      for domain in vendor["domains"]:
        if domain in str(items):
          vendor_results.extend(items)
          break

    # é‡è¤‡é™¤å»
    seen_urls = set()
    unique_results = []
    for item in vendor_results:
      url = item.get("url", "")
      if url and url not in seen_urls:
        seen_urls.add(url)
        unique_results.append(item)

    # LLMã§ç®‡æ¡æ›¸ãã«è¦ç´„
    bullets = _create_llm_summarized_bullets(unique_results[:5], vendor["name"], num_bullets=3)

    vendor_bullets.append({
      "name": vendor["name"],
      "emoji": vendor["emoji"],
      "bullets": bullets,
      "gradient": vendor["gradient"],
    })

  # Slidevãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ç”Ÿæˆ
  slide_content = f"""---
theme: apple-basic
highlighter: shiki
class: text-center
drawings:
  persist: false
fonts:
  sans: 'Inter'
  serif: 'Roboto Slab'
  mono: 'Fira Code'
---

# ğŸš€ {topic}
## {mvp_version}

<div class="pt-12">
  <span class="px-2 py-1 rounded" style="background: #6366f1; color: white;">
    {month_ja()}
  </span>
</div>

---
layout: intro
class: text-left
---

## ğŸ“‹ Agenda

<v-clicks>

"""

  # ã‚¢ã‚¸ã‚§ãƒ³ãƒ€é …ç›®
  for vb in vendor_bullets:
    slide_content += f"- {vb['emoji']} **{vb['name']}** - æœ€æ–°ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ\n"

  slide_content += "\n</v-clicks>\n\n"

  # å„ãƒ™ãƒ³ãƒ€ãƒ¼ã®ã‚¹ãƒ©ã‚¤ãƒ‰
  for vb in vendor_bullets:
    slide_content += f"""---
layout: two-cols
class: px-2
---

## {vb['emoji']} {vb['name']}

<v-clicks>

{chr(10).join(vb['bullets'])}

</v-clicks>

::right::

<div class="flex items-center justify-center h-full">
  <div style="width: 280px; height: 180px; background: {vb['gradient']}; border-radius: 12px; display: flex; align-items: center; justify-content: center; color: white; font-size: 20px; font-weight: bold; box-shadow: 0 10px 30px rgba(0,0,0,0.2);">
    {vb['name']}
  </div>
</div>

"""

  # ã¾ã¨ã‚ã‚¹ãƒ©ã‚¤ãƒ‰
  slide_content += f"""---
layout: end
class: text-center
---

# âœ¨ ã¾ã¨ã‚

<div class="mt-8">

## å®Œäº† ğŸ‰

å…¨6ç¤¾ã®AIæœ€æ–°æƒ…å ±ã‚’çµ±åˆã—ã¾ã—ãŸ

</div>

<div style="position: absolute; bottom: 1.5rem; right: 1.5rem; font-size: 0.875rem; opacity: 0.5;">
  Generated by SlidePilot AI ({mvp_version})
</div>

"""

  return slide_content

# -------------------
# Tavily æ¤œç´¢
# -------------------
def tavily_search(
  query: str,
  max_results: int = 8,
  include_domains: Optional[List[str]] = None,
  time_range: str = "month", # day/week/month/year
  ) -> Dict:
  endpoint = "https://api.tavily.com/search"
  payload = {
    "api_key": TAVILY_API_KEY,
    "query": query,
    "search_depth": "advanced",
    "include_answers": True,
    "max_results": max_results,
    "time_range": time_range, # ç›´è¿‘ã®æƒ…å ±ã«é™å®š
  }
  if include_domains:
    payload["include_domains"] = include_domains
  r = requests.post(endpoint, json=payload, timeout=60)
  r.raise_for_status()
  return r.json()

def tavily_collect_context(
  queries: List[Union[str, Dict[str, Any]]],
  max_per_query: int = 6,
  default_time_range: str = "month",
) -> Dict[str, List[Dict[str, str]]]:
  """
  queriesã¯ä»¥ä¸‹ã®ï¼’å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆ:
    - "plain text"
    - {"q": "...", "include_domains": ["example.com", ...], "time_range": "week"}
  """
  seen = set()
  out: Dict[str, List[Dict[str, str]]] = {}
  for q in queries:
    if isinstance(q, dict):
      qtext = q.get("q", "")
      inc = q.get("include_domains")
      tr = q.get("time_range", default_time_range)
    else:
      qtext = q
      inc = None
      tr = default_time_range

    if not qtext:
      continue

    data = tavily_search(qtext, max_results=max_per_query, include_domains=inc, time_range=tr)
    items = []
    for r in data.get("results", []):
      url = r.get("url")
      if not url or url in seen:
        continue
      seen.add(url)
      items.append({
        "title": (r.get("title") or "")[:160],
        "url": url,
        "content": r.get("content" or "").replace("\n", " ")[:600],
      })
      out[qtext] = items
  return out

def context_to_bullets(ctx: List[Dict[str, str]]) -> List[str]:
  # LLMã«æ¸¡ã—ã‚„ã™ã„ã€å‡ºå…¸ä»˜ãã®çŸ­æ–‡ç®‡æ¡æ›¸ãã«ã™ã‚‹
  bullets = []
  for q, items in ctx.items():
    bullets.append(f"### Query: {q}")
    for it in items:
      title = it.get("title")
      url = it.get("url")
      content = it.get("content").replace("\n", " ")
      bullets.append(f"- {title} - {content} - [source]({url})")
    bullets.append("") # ç©ºè¡Œã§åŒºåˆ‡ã‚‹
  return "\n".join(bullets)

# -------------------
# Slidev Test Tool (Phase 0: MVP)
# -------------------
@tool("generate_slidev_test")
def generate_slidev_test(topic: str = "AIæœ€æ–°æƒ…å ±") -> str:
  """Slidevã§ç°¡æ˜“ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”Ÿæˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ãƒ»ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ï¼‰"""

  # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸSlidevãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³
  slide_content = f"""---
theme: apple-basic
layout: cover
background: #ffffff
---

# {topic}
2025å¹´10æœˆç‰ˆ

---
layout: intro
---

## Agenda
- Microsoft AI æœ€æ–°æƒ…å ±
- OpenAI ã®å‹•å‘
- Google Gemini ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
- ã¾ã¨ã‚

---

## Microsoft AI

- **Azure OpenAI Service**: GPT-4 Turboå¯¾å¿œ
- **Copilot Studio**: ãƒãƒ¼ã‚³ãƒ¼ãƒ‰AIé–‹ç™º
- **Semantic Kernel**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–‹ç™ºãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

---
layout: two-cols
---

## OpenAI æœ€æ–°æƒ…å ±

::left::

### GPT-4 Turbo
- ã‚³ã‚¹ãƒˆå‰Šæ¸›
- 128K context window
- JSON mode

::right::

### DALL-E 3
- ã‚ˆã‚Šé«˜ç²¾åº¦ãªç”»åƒç”Ÿæˆ
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç†è§£å‘ä¸Š

---

## Google Gemini

- **Gemini Pro**: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AI
- **Vertex AIçµ±åˆ**: ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºå‘ã‘
- **Duet AI**: Google Workspaceé€£æº

---
layout: end
---

# ã¾ã¨ã‚

AIæŠ€è¡“ã¯æ€¥é€Ÿã«é€²åŒ–ä¸­
å„ç¤¾ã®æœ€æ–°æƒ…å ±ã‚’ã‚­ãƒ£ãƒƒãƒã‚¢ãƒƒãƒ—ã—ã¾ã—ã‚‡ã†

"""

  # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
  slide_dir = Path(__file__).parent / "slides"
  slide_dir.mkdir(parents=True, exist_ok=True)

  # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
  slug = _slugify_en(topic) or "test"
  md_path = slide_dir / f"{slug}_slidev_test.md"
  md_path.write_text(slide_content, encoding="utf-8")

  # Slidev PDFå‡ºåŠ›
  pdf_path = slide_dir / f"{slug}_slidev_test.pdf"

  slidev = shutil.which("slidev")
  if slidev:
    try:
      # Slidev export ã‚³ãƒãƒ³ãƒ‰
      subprocess.run(
        ["slidev", "export", str(md_path),
         "--output", str(pdf_path),
         "--format", "pdf",
         "--timeout", "60000"],  # 60ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        check=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        timeout=90  # ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
      )
      return json.dumps({
        "status": "success",
        "slide_path": str(pdf_path.relative_to(slide_dir.parent)),
        "title": topic,
        "message": f"Slidevã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {pdf_path.name}"
      }, ensure_ascii=False)
    except subprocess.TimeoutExpired:
      return json.dumps({
        "status": "error",
        "slide_path": str(md_path.relative_to(slide_dir.parent)),
        "title": topic,
        "error": "PDFç”ŸæˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ90ç§’è¶…éï¼‰",
        "message": "Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ä¿å­˜ã—ã¾ã—ãŸ"
      }, ensure_ascii=False)
    except subprocess.CalledProcessError as e:
      # PDFç”Ÿæˆå¤±æ•—æ™‚ã¯MDã®ã¿è¿”ã™
      error_msg = e.stderr.decode() if e.stderr else str(e)
      return json.dumps({
        "status": "partial",
        "slide_path": str(md_path.relative_to(slide_dir.parent)),
        "title": topic,
        "error": f"PDFç”Ÿæˆå¤±æ•—: {error_msg}",
        "message": "Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ä¿å­˜ã—ã¾ã—ãŸ"
      }, ensure_ascii=False)
  else:
    # slidevæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ™‚
    return json.dumps({
      "status": "md_only",
      "slide_path": str(md_path.relative_to(slide_dir.parent)),
      "title": topic,
      "message": "slidevãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Markdownã®ã¿ä¿å­˜ã—ã¾ã—ãŸ"
    }, ensure_ascii=False)


# -------------------
# State
# -------------------
class State(TypedDict):
  """LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®çŠ¶æ…‹ç®¡ç†"""

  # å…¥åŠ›
  topic: str                                    # ã‚¹ãƒ©ã‚¤ãƒ‰ã®ä¸»é¡Œ

  # æƒ…å ±åé›† (Node A)
  sources: Dict[str, List[Dict[str, str]]]      # Tavilyæ¤œç´¢çµæœ
  context_md: str                               # æ¤œç´¢çµæœã®Markdown

  # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ (Node B-D)
  key_points: List[str]                         # é‡è¦ãƒã‚¤ãƒ³ãƒˆ5å€‹
  toc: List[str]                                # ç›®æ¬¡5-8é …ç›®
  slide_md: str                                 # Marpã‚¹ãƒ©ã‚¤ãƒ‰æœ¬æ–‡
  title: str                                    # ã‚¹ãƒ©ã‚¤ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«

  # è©•ä¾¡ (Node E)
  score: float                                  # ç·åˆã‚¹ã‚³ã‚¢ (0-10)
  subscores: Dict[str, float]                   # é …ç›®åˆ¥ã‚¹ã‚³ã‚¢
  reasons: Dict[str, str]                       # è©•ä¾¡ç†ç”±
  suggestions: List[str]                        # æ”¹å–„ææ¡ˆ
  risk_flags: List[str]                         # ãƒªã‚¹ã‚¯äº‹é …
  passed: bool                                  # åˆæ ¼åˆ¤å®š (>=8.0)
  feedback: str                                 # ç·åˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
  attempts: int                                 # ãƒªãƒˆãƒ©ã‚¤å›æ•° (æœ€å¤§3)

  # å‡ºåŠ› (Node F)
  slide_path: str                               # ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

  # ã‚·ã‚¹ãƒ†ãƒ 
  error: str                                    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
  log: List[str]                                # å®Ÿè¡Œãƒ­ã‚°

# =======================
# Node A: Tavily æƒ…å ±åé›† (ç›´è¿‘2ãƒ¶æœˆ & å…¬å¼ãƒ‰ãƒ¡ã‚¤ãƒ³)
# =======================
@traceable(run_name="a_tavily_collect")
def collect_info(state: State) -> State:
  topic = state.get("topic") or "AIæœ€æ–°æƒ…å ±"

  # JSTã®ç¾åœ¨æ—¥æ™‚ ã¨ã€€æœˆè‹±èªè¡¨è¨˜ã‚’å–å¾—
  def month_en_for(dt: datetime) -> str:
    months = ["January","February","March","April","May","June",
              "July","August","September","October","November","December"]
    return f"{months[dt.month-1]} {dt.year}"

  now = now_jst()
  # å…ˆæœˆã¯ã€æœˆæœ«æ—¥ã®1æ—¥ã«ãªã‚‹
  prev_month_dt = now.replace(day=1) - timedelta(days=1)
  # ç›´è¿‘2ãƒ¶æœˆ
  month_labels = [month_en_for(now), month_en_for(prev_month_dt)]

  # ãƒ™ãƒ³ãƒ€ãƒ¼æ¯ã®å…¬å¼ãƒ‰ãƒ¡ã‚¤ãƒ³
  vendors_domains = [
        (["azure.microsoft.com","news.microsoft.com","learn.microsoft.com"],
         ["Microsoft AI updates", "Azure OpenAI updates"]),
        (["openai.com"], ["OpenAI announcements","OpenAI updates"]),
        (["blog.google","ai.googleblog.com","research.google"], ["Google AI updates", "Gemini updates"]),
        (["aws.amazon.com"], ["AWS Bedrock updates","Amazon AI updates"]),
        (["ai.meta.com"], ["Meta AI updates", "Llama updates"]),
        (["anthropic.com"], ["Anthropic Claude updates","Claude announcements"]),
    ]

  # â˜… ç›´è¿‘2ãƒ¶æœˆ Ã— å„ç¤¾ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ§‹æˆ
  queries: List[Dict[str, Any]] = []
  for m in month_labels:
    for domains, patterns in vendors_domains:
      for p in patterns:
        queries.append({"q": f"{p} {m}", "include_domains": domains, "time_range": "month"})
  try:
    sources = tavily_collect_context(queries, max_per_query=6, default_time_range="month")
    context_md = context_to_bullets(sources)
    return {
      "sources": sources,
      "context_md": context_md,
      "log": _log(state, f"[tavily] months={month_labels} queries={len(queries)}")
    }
  except Exception as e:
    return {"error": f"tavily_error: {e}", "log": _log(state, f"[tavily] EXCEPTION {e}")}

# -------------------
# Node B: é‡è¦ãƒã‚¤ãƒ³ãƒˆç”Ÿæˆ
# -------------------
@traceable(run_name="b_generate_key_points")
def generate_key_points(state: State) -> Dict:
  topic = state.get("topic") or "AIæœ€æ–°æƒ…å ±"
  ctx = state.get("context_md") or ""
  prompt = [
    ("system", "ã‚ãªãŸã¯Solution Engineerã§ã™ã€‚ã“ã‚Œã‹ã‚‰Marpã‚¹ãƒ©ã‚¤ãƒ‰ã§AIæœ€æ–°æƒ…å ±ã‚’ç™ºè¡¨ã—ã¾ã™ã€‚"),
      ("user",
        "ä»¥ä¸‹ã®â€œæœ€æ–°æƒ…å ±ã‚µãƒãƒªï¼ˆå‡ºå…¸ä»˜ãï¼‰â€ã‚’å‚è€ƒã«ã€ç™ºè¡¨ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’å„ç¤¾5å€‹ã€"
        "çŸ­ã„ç®‡æ¡æ›¸ãã§ã€‚URLã‚‚å«ã‚ã¦ãã ã•ã„ã€‚\n\n"
        f"[æœ€æ–°æƒ…å ±ã‚µãƒãƒª]\n{ctx}\n\n[ãƒˆãƒ”ãƒƒã‚¯]\n{topic}")
  ]
  try:
    msg = llm.invoke(prompt)
    bullets = _strip_bullets(msg.content.splitlines())[:5] or [msg.content.strip()] # ç®‡æ¡æ›¸ããŒå–ã‚Œãªã‹ã£ãŸã‚‰ã€ã›ã‚ã¦å…ƒã®æ–‡ç« ã‚’ãã®ã¾ã¾ä½¿ã†ã€‚
    return {"key_points": bullets, "log": _log(state, f"[key_points] {bullets}")}
  except Exception as e:
    return {"error": f"key_points_error: {e}", "log": _log(state, f"[key_points] EXCEPTION {e}")}

# -------------------
# Node C: ç›®æ¬¡ç”Ÿæˆ
# -------------------
@traceable(run_name="c_generate_toc")
def generate_toc(state: State) -> Dict:
  key_points = state.get("key_points") or []
  prompt = [
        ("system", "ã‚ãªãŸã¯Solution Engineerã§ã™ã€‚Marpã‚¹ãƒ©ã‚¤ãƒ‰ã®æ§‹æˆï¼ˆç›®æ¬¡ï¼‰ã‚’ä½œã‚Šã¾ã™ã€‚"),
        ("user",
         "ä»¥ä¸‹ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã€5ã€œ8å€‹ã®ç« ç«‹ã¦ï¼ˆé…åˆ—ï¼‰ã‚’ JSON ã® {\"toc\": [ ... ]} å½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚\n\n"
         "é‡è¦ãƒã‚¤ãƒ³ãƒˆ:\n- " + "\n- ".join(key_points))
  ]
  try:
    msg = llm.invoke(prompt)
    try:
      data = json.loads(_find_json(msg.content) or msg.content)
      toc = [s.strip() for s in data.get("toc", []) if s.strip()]
    except Exception as e:
      toc = _strip_bullets(msg.content.splitlines())
      toc = toc[:8] or ["ã¯ã˜ã‚ã«", "èƒŒæ™¯", "å®Ÿè£…æ‰‹é †", "è©•ä¾¡ã¨æ”¹å–„", "å…¬é–‹ãƒ»é‹ç”¨", "ã¾ã¨ã‚"]
    return {"toc": toc, "error": "", "log": _log(state, f"[toc] {toc}")}
  except Exception as e:
    return {"error": f"toc_error: {e}", "log": _log(state, f"[toc] EXCEPTION {e}")}

# -------------------
# Node D: ã‚¹ãƒ©ã‚¤ãƒ‰æœ¬æ–‡ï¼ˆMarpï¼‰ç”Ÿæˆ
# -------------------
@traceable(run_name="d_generate_slide_md")
def write_slides(state: State) -> Dict:
  ctx = state.get("context_md") or "" # Tavilyã‹ã‚‰ã®è¦ç´„ï¼ˆç®‡æ¡æ›¸ãï¼‰
  sources = state.get("sources") or {}

  # å‚è€ƒãƒªãƒ³ã‚¯
  refs = []
  for items in sources.values():
    for it in items[:2]:
      refs.append(f"- **{it['title']}** â€” {it['url']}")
  refs_md = "\n".join(refs)

  # ã‚¿ã‚¤ãƒˆãƒ«ã¯LLMã«ä»»ã›ãšã€å½“æœˆã§å›ºå®š
  ja_title = f"{month_ja()} AIæœ€æ–°æƒ…å ±ã¾ã¨ã‚"

  prompt = [
      ("system",
        "ã‚ãªãŸã¯Microsoftã®Solution Engineerã§ã€Marpå½¢å¼ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä½œã‚Šã¾ã™ã€‚"
        "å‡ºåŠ›ã¯ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã§å›²ã¾ãšã€ã‚¹ãƒ©ã‚¤ãƒ‰åŒºåˆ‡ã‚Šï¼ˆ---ï¼‰ã¯å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚"
        "å„ã‚¹ãƒ©ã‚¤ãƒ‰ã¯å¿…ãš H2 è¦‹å‡ºã—ï¼ˆ## ï¼‰ã§é–‹å§‹ã€‚ã‚¿ã‚¤ãƒˆãƒ«ã‚¹ãƒ©ã‚¤ãƒ‰ã«ç™ºè¡¨è€…åã¯æ›¸ã‹ãªã„ã§ãã ã•ã„ã€‚"
        "é‡è¦: ä»¥ä¸‹ã®â€œæœ€æ–°æƒ…å ±ã‚µãƒãƒªâ€ã®ç¯„å›²å†…ã®äº‹å®Ÿã®ã¿ã«åŸºã¥ã„ã¦ä½œæˆã—ã€ã‚µãƒãƒªã«ç„¡ã„æƒ…å ±ã¯æ›¸ã‹ãªã„ã§ãã ã•ã„ã€‚"),
      ("user",
        "æœ€æ–°æƒ…å ±ã‚µãƒãƒªï¼ˆå‡ºå…¸ä»˜ãï¼‰:\n"
        f"{ctx}\n\n"
        "è¦ä»¶:\n"
        f"- ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè¡¨ç´™ã®å¤§è¦‹å‡ºã—ï¼‰: {ja_title}\n"
        "- 1ãƒšãƒ¼ã‚¸ç›®ã¯ # è¦‹å‡ºã—ã¨çŸ­ã„ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ï¼ˆç™ºè¡¨è€…åã¯æ›¸ã‹ãªã„ï¼‰\n"
        "- 2ãƒšãƒ¼ã‚¸ç›®ã¯ Agendaï¼ˆç« ç«‹ã¦ã‚’åˆ—æŒ™ï¼‰\n"
        "- ä»¥é™ã¯å„ç¤¾ã”ã¨ã®AIæœ€æ–°æƒ…å ±ã‚’ç°¡æ½”ã«ã€‚å„é …ç›®ã«URLã‚’å«ã‚ã‚‹\n"
        "- å„ç« ã¯å¿…ãš H2ï¼ˆ## ï¼‰ã§å§‹ã‚ã‚‹")
  ]

  try:
    msg = llm.invoke(prompt)

    # Nullå€¤ãƒã‚§ãƒƒã‚¯ã¨å‡¦ç†
    if msg.content is None:
        print(f"[WARNING] write_slides: msg.content is None, using fallback")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”Ÿæˆ
        slide_md = f"""# {ja_title}

                    ## Agenda
                    - Microsoft AI æœ€æ–°æƒ…å ±
                    - Azure OpenAI æœ€æ–°æƒ…å ±
                    - OpenAI æœ€æ–°æƒ…å ±
                    - Google AI æœ€æ–°æƒ…å ±
                    - ã¾ã¨ã‚

                    ---

                    ## Microsoft AI æœ€æ–°æƒ…å ±

                    æœ€æ–°æƒ…å ±ã‚’å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

                    ---

                    ## ã¾ã¨ã‚

                    AIæŠ€è¡“ã®æœ€æ–°å‹•å‘ã‚’ãŠä¼ãˆã—ã¾ã—ãŸã€‚
                    """
    else:
        slide_md = msg.content.strip()

    # å„ç¨®æ•´å½¢ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®é™¤å»ã€ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã®æŒ¿å…¥ã€é‡è¤‡ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã®åœ§ç¸®ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã®è¨­å®šã€ç™ºè¡¨è€…è¡Œã®é™¤å»ï¼‰
    if slide_md:
        slide_md = _strip_whole_code_fence(slide_md)
        slide_md = _insert_separators(slide_md)
        slide_md = _double_separators(slide_md)
        slide_md = _ensure_marp_header(slide_md, _clean_title(ja_title))
        slide_md = _remove_presenter_lines(slide_md)
    return {"slide_md": slide_md, "title": ja_title,
                "error": "", "log": _log(state, f"[slides] generated ({len(slide_md)} chars)")}
  except Exception as e:
    return {"error": f"slides_error: {e}", "log": _log(state, f"[slides] EXCEPTION {e}")}

# -------------------
# Node D-Slidev: ã‚¹ãƒ©ã‚¤ãƒ‰æœ¬æ–‡ï¼ˆSlidevï¼‰ç”Ÿæˆ (Phase 1 - MVP-1)
# -------------------
@traceable(run_name="d_generate_slide_slidev")
def write_slides_slidev(state: State) -> Dict:
  """Slidevå½¢å¼ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”Ÿæˆï¼ˆå…¨6ç¤¾å¯¾å¿œï¼‰"""
  sources = state.get("sources") or {}
  topic = state.get("topic") or "AIæœ€æ–°æƒ…å ±"

  # ã‚¿ã‚¤ãƒˆãƒ«ã¯å½“æœˆã§å›ºå®š
  ja_title = f"{month_ja()} AIæœ€æ–°æƒ…å ±ã¾ã¨ã‚"

  try:
    # Slidevãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ç”Ÿæˆ
    slide_md = _generate_multi_vendor_slides_integrated(
      topic=ja_title,
      sources=sources,
      mvp_version="AI Industry Report 2025"
    )

    return {
      "slide_md": slide_md,
      "title": ja_title,
      "error": "",
      "log": _log(state, f"[slides_slidev] generated ({len(slide_md)} chars, 6 vendors)")
    }

  except Exception as e:
    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”Ÿæˆ
    fallback_md = f"""---
theme: apple-basic
highlighter: shiki
class: text-center
---

# ğŸš€ {ja_title}
## ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ

<div class="pt-12">
  <span class="px-2 py-1 rounded" style="background: #ef4444; color: white;">
    Error: {str(e)}
  </span>
</div>

---

## âš ï¸ ã‚¨ãƒ©ãƒ¼è©³ç´°

ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

- æ¤œç´¢çµæœã®å–å¾—ã«å¤±æ•—ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
- ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„

"""
    return {
      "slide_md": fallback_md,
      "title": ja_title,
      "error": f"slides_slidev_error: {e}",
      "log": _log(state, f"[slides_slidev] EXCEPTION {e} - using fallback")
    }

# -------------------
# Node E: è©•ä¾¡ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰å‰æï¼‰
# -------------------
# MAX_ATTEMPTS = 3
# @traceable(run_name="e_evaluate_slides")
# def evaluate_slides(state: State) -> Dict:
#   if state.get("error"):
#     return {}
#   slide_md = state.get("slide_md") or ""
#   toc = state.get("toc") or []
#   topic = state.get("topic") or ""
#   eval_guide = (
#         "è©•ä¾¡è¦³ç‚¹ã¨é‡ã¿:\n"
#         "- structure(0.20): ã‚¹ãƒ©ã‚¤ãƒ‰ã®æµã‚Œã€ç« ç«‹ã¦ã€1ã‚¹ãƒ©ã‚¤ãƒ‰1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n"
#         "- practicality(0.25): å®Ÿå‹™ã«ä½¿ãˆã‚‹å…·ä½“æ€§ï¼ˆæ‰‹é †ã€ã‚³ãƒ¼ãƒ‰ä¾‹ã€æ³¨æ„ç‚¹ï¼‰\n"
#         "- accuracy(0.25): äº‹å®Ÿãƒ»APIä»•æ§˜ãƒ»ç”¨èªã®æ­£ç¢ºã•\n"
#         "- readability(0.15): ç°¡æ½”æ˜ç­ã€è¦–èªæ€§ï¼ˆç®‡æ¡æ›¸ãã®ç²’åº¦ï¼‰\n"
#         "- conciseness(0.15): å†—é•·æ€§ã®å°‘ãªã•\n"
#         "åˆæ ¼: score >= 8.0\n"
#   )
#   prompt = [
#         ("system",
#          "ã‚ãªãŸã¯Cloud Solution Architectã§ã™ã€‚ä»¥ä¸‹ã®Marpã‚¹ãƒ©ã‚¤ãƒ‰Markdownã‚’ã€"
#          "æŒ‡å®šã®è¦³ç‚¹ãƒ»é‡ã¿ã§å³å¯†ã«æ¡ç‚¹ã—ã¾ã™ã€‚å‡ºåŠ›ã¯JSONã®ã¿ã€‚"),
#         ("user",
#          f"Topic: {topic}\nTOC: {json.dumps(toc, ensure_ascii=False)}\n\n"
#          "Slides (Marp Markdown):\n<<<SLIDES\n" + slide_md + "\nSLIDES\n\n"
#          "Evaluation Guide:\n<<<EVAL\n" + eval_guide + "\nEVAL\n\n"
#          "Return strictly this JSON schema:\n"
#          "{\n"
#          "  \"score\": number,\n"
#          "  \"subscores\": {\"structure\": number, \"practicality\": number, \"accuracy\": number, \"readability\": number, \"conciseness\": number},\n"
#          "  \"reasons\": {\"structure\": string, \"practicality\": string, \"accuracy\": string, \"readability\": string, \"conciseness\": string},\n"
#          "  \"suggestions\": [string],\n"
#          "  \"risk_flags\": [string],\n"
#          "  \"pass\": boolean,\n"
#          "  \"feedback\": string\n"
#          "}"
#         )]
#   try:
#     msg = llm.invoke(prompt)
#     raw = msg.content or ""
#     js = _find_json(raw) or raw
#     data = json.loads(js)
#
#     score = float(data.get("score", 0.0))
#     subscores = data.get("subscores") or {}
#     reasons = data.get("reasons") or {}
#     suggestions = data.get("suggestions") or []
#     risk_flags = data.get("risk_flags") or []
#     passed = bool(data.get("pass", score >= 8.0))
#     feedback = str(data.get("feedback", "")).strip()
#     attempts = (state.get("attempts") or 0) + 1
#
#     return {
#       "score": score,
#       "subscores": subscores,
#       "reasons": reasons,
#       "suggestions": suggestions,
#       "risk_flags": risk_flags,
#       "passed": passed,
#       "feedback": feedback,
#       "attempts": attempts,
#       "log": _log(state, f"[evaluate] score={score:.2f} pass={passed} attempts={attempts}")
#     }
#   except Exception as e:
#     return {"error": f"eval_error: {e}", "log": _log(state, f"[evaluate] EXCEPTION {e}")}
#
# def route_after_eval(state: State) -> str:
#     if (state.get("attempts") or 0) >= MAX_ATTEMPTS:
#         return "ok"
#     return "ok" if state.get("passed") else "retry"

# -------------------
# Node F: ä¿å­˜ & Marpãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
# -------------------
@traceable(run_name="f_save_and_render")
def save_and_render(state: State) -> Dict:
  if state.get("error"):
    return {}
  slide_md = state.get("slide_md") or ""
  title = state.get("title") or "AIã‚¹ãƒ©ã‚¤ãƒ‰"

  # ã‚¹ãƒ©ã‚¤ãƒ‰å†…å®¹ãŒç©ºã®å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
  if not slide_md.strip():
    return {"error": "slide_md is empty", "log": _log(state, "[save] ERROR: slide_md is empty")}

  # ã‚¹ãƒ©ã‚¤ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«åã®è‹±èªè¡¨è¨˜ã‚’ç”Ÿæˆ
  slug_prompt = [
        ("system", "You create concise English slugs for filenames."),
        ("user",
         "Convert the following Japanese title into a short English filename base (<=6 words). "
         "Only letters and spaces; no punctuation or numbers.\n\n"
         f"Title: {title}")
    ]
  emsg = llm.invoke(slug_prompt)
  file_stem = _slugify_en(emsg.content.strip()) or _slugify_en(title)

  slide_dir = Path(__file__).parent / "slides"
  slide_dir.mkdir(parents=True, exist_ok=True)
  slide_md_path = slide_dir / f"{file_stem}_slides.md"
  slide_md_path.write_text(slide_md, encoding="utf-8")

  marp = shutil.which("marp")
  out_path = str(slide_md_path)
  if marp and SLIDE_FORMAT in ["pdf", "png", "html"]:
    ext = SLIDE_FORMAT
    out_file = slide_dir / f"{file_stem}.{ext}"
    try:
      subprocess.run(
                [marp, str(slide_md_path), f"--{ext}", "-o", str(out_file)],
                check=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
            )
      out_path = str(out_file)
      log_msg = f"[marp] generated {ext} -> {out_file}"
    except subprocess.CalledProcessError as e:
      log_msg = f"[marp] marp-cli failed: {e}"
  else:
    if not marp and SLIDE_FORMAT:
      log_msg = "[marp] marp-cli not found â€“ skipped rendering (left .md)."
    else:
      log_msg = "[marp] rendering skipped (SLIDE_FORMAT not set)."
  return {
    "slide_path": out_path,
    "log": _log(state, log_msg)
  }

# -------------------
# Node F-Slidev: ä¿å­˜ & Slidevãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° (Phase 1 - MVP-2)
# -------------------
@traceable(run_name="f_save_and_render_slidev")
def save_and_render_slidev(state: State) -> Dict:
  """Slidevå½¢å¼ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä¿å­˜ã—ã¦PDFç”Ÿæˆ"""
  if state.get("error"):
    return {}

  slide_md = state.get("slide_md") or ""
  title = state.get("title") or "AIã‚¹ãƒ©ã‚¤ãƒ‰"

  # ã‚¹ãƒ©ã‚¤ãƒ‰å†…å®¹ãŒç©ºã®å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
  if not slide_md.strip():
    return {
      "error": "slide_md is empty",
      "log": _log(state, "[save_slidev] ERROR: slide_md is empty")
    }

  # ã‚¹ãƒ©ã‚¤ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«åã®è‹±èªè¡¨è¨˜ã‚’ç”Ÿæˆ
  slug_prompt = [
    ("system", "You create concise English slugs for filenames."),
    ("user",
     "Convert the following Japanese title into a short English filename base (<=6 words). "
     "Only letters and spaces; no punctuation or numbers.\n\n"
     f"Title: {title}")
  ]

  try:
    emsg = llm.invoke(slug_prompt)
    file_stem = _slugify_en(emsg.content.strip()) or _slugify_en(title)
  except Exception:
    file_stem = _slugify_en(title) or "ai-latest-info"

  slide_dir = Path(__file__).parent / "slides"
  slide_dir.mkdir(parents=True, exist_ok=True)
  slide_md_path = slide_dir / f"{file_stem}_slidev.md"
  slide_md_path.write_text(slide_md, encoding="utf-8")

  # Slidev PDFç”Ÿæˆ
  slidev = shutil.which("slidev")
  out_path = str(slide_md_path)

  if slidev and SLIDE_FORMAT == "pdf":
    pdf_file = slide_dir / f"{file_stem}_slidev.pdf"
    try:
      subprocess.run(
        ["slidev", "export", str(slide_md_path),
         "--output", str(pdf_file),
         "--format", "pdf",
         "--timeout", "60000"],  # 60ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        check=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        timeout=90  # ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
      )
      out_path = str(pdf_file)
      log_msg = f"[slidev] generated PDF -> {pdf_file.name}"
    except subprocess.TimeoutExpired:
      log_msg = f"[slidev] PDF generation timeout (90s) - MD saved at {slide_md_path.name}"
    except subprocess.CalledProcessError as e:
      error_msg = e.stderr.decode() if e.stderr else str(e)
      log_msg = f"[slidev] export failed: {error_msg[:100]} - MD saved"
  else:
    if not slidev:
      log_msg = "[slidev] slidev-cli not found â€“ skipped rendering (left .md)."
    else:
      log_msg = f"[slidev] rendering skipped (SLIDE_FORMAT={SLIDE_FORMAT}, only pdf supported)."

  return {
    "slide_path": out_path,
    "log": _log(state, log_msg)
  }

# -------------------
# ã‚°ãƒ©ãƒ•æ§‹ç¯‰ (Phase 1 - MVP-3)
# -------------------
graph_builder = StateGraph(State)
graph_builder.add_node("collect_info", collect_info)
graph_builder.add_node("generate_key_points", generate_key_points)
graph_builder.add_node("generate_toc", generate_toc)

# Marpãƒãƒ¼ãƒ‰ï¼ˆå‚è€ƒç”¨ã«ä¿æŒã€ç¾åœ¨ã¯æœªä½¿ç”¨ï¼‰
# graph_builder.add_node("write_slides", write_slides)
# graph_builder.add_node("save_and_render", save_and_render)

# Slidevãƒãƒ¼ãƒ‰ï¼ˆPhase 1ã§ä½¿ç”¨ï¼‰
graph_builder.add_node("write_slides_slidev", write_slides_slidev)
graph_builder.add_node("save_and_render_slidev", save_and_render_slidev)

# è©•ä¾¡ãƒãƒ¼ãƒ‰ï¼ˆç¾åœ¨ã¯ç„¡åŠ¹åŒ–ï¼‰
# graph_builder.add_node("evaluate_slides", evaluate_slides)

# ã‚¨ãƒƒã‚¸å®šç¾©ï¼ˆSlidevãƒ•ãƒ­ãƒ¼ï¼‰
graph_builder.add_edge(START, "collect_info")
graph_builder.add_edge("collect_info", "generate_key_points")
graph_builder.add_edge("generate_key_points", "generate_toc")
graph_builder.add_edge("generate_toc", "write_slides_slidev")
graph_builder.add_edge("write_slides_slidev", "save_and_render_slidev")
graph_builder.add_edge("save_and_render_slidev", END)

# Marpãƒ•ãƒ­ãƒ¼ï¼ˆå‚è€ƒç”¨ã«ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
# graph_builder.add_edge("generate_toc", "write_slides")
# graph_builder.add_edge("write_slides", "save_and_render")
# graph_builder.add_edge("save_and_render", END)

# è©•ä¾¡ãƒ«ãƒ¼ãƒ—ï¼ˆç¾åœ¨ã¯ç„¡åŠ¹åŒ–ï¼‰
# graph_builder.add_conditional_edges(
#   "evaluate_slides",
#   route_after_eval,
#   {"retry": "generate_key_points", "ok": "save_and_render"}
# )

graph = graph_builder.compile()

# -------------------
# å®Ÿè¡Œ
# -------------------
if __name__ == "__main__":
  print("LangSmith Tracing:", os.getenv("LANGCHAIN_TRACING_V2"),
      "| Project:", os.getenv("LANGCHAIN_PROJECT"))
  init: State = {
    "topic": "LangGraph Ã— LangSmith Ã— OpenAI Ã— Tavilyã§ä½œã‚‹ï¼šæœ€æ–°AIå‹•å‘ã‚¹ãƒ©ã‚¤ãƒ‰",
    "key_points": [], "toc": [], "slide_md": "",
    "score": 0.0,
    "subscores": {}, "reasons": {},
    "suggestions": [], "risk_flags": [],
    "passed": False, "feedback": "",
    "title": "", "slide_path": "",
    "attempts": 0, "error": "", "log": [],
    "context_md": "", "sources": {}
  }

  config: RunnableConfig = {
    "run_name": "tavily_marp_agent",
    "tags": ["marp", "langgraph", "langsmith", "openai", "tavily"],
    "metadata": {"env": "dev", "date": datetime.now(timezone.utc).isoformat()},
    "recursive_limit": 60,
  }
  out = graph.invoke(init, config=config)

  print("\n=== RESULT ===")
  if out.get("error"):
    print("ERROR:", out["error"])
  else:
    print("Title    :", out.get("title"))
    print("Slide    :", out.get("slide_path"))
    # print("Score    :", out.get("score"))
    # print("Passed   :", out.get("passed"))
  print("\n=== LOGS ===")
  for line in out.get("log", []):
    print(line)