# LangGraph Ã— LangSmith Ã— OpenAI Ã— Tavily Ã— Slidev
# ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆPDF/YouTube/ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œï¼‰
# ãƒ•ãƒ­ãƒ¼: æƒ…å ±åé›† -> ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæŠ½å‡º -> ç›®æ¬¡ç”Ÿæˆ -> ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆ -> è©•ä¾¡ -> ä¿å­˜

# å…±é€šãƒ­ã‚¸ãƒƒã‚¯ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from slide_core import (
    # ç’°å¢ƒå¤‰æ•°ãƒ»å®šæ•°
    TAVILY_API_KEY, SLIDE_FORMAT, MARP_THEME, MARP_PAGINATE,
    # LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
    llm,
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
    _log, _strip_bullets, _slugify_en, _find_json,
    _ensure_marp_header, _insert_separators, _double_separators,
    _clean_title, _strip_whole_code_fence, _remove_presenter_lines,
    # æ—¥æ™‚é–¢æ•°
    JST, now_jst, today_iso, month_ja, month_en, get_today_jst,
    # Slidevç”Ÿæˆé–¢æ•°
    _get_all_vendors_info, _create_llm_summarized_bullets,
    _generate_multi_vendor_slides_integrated,
    # Tavilyæ¤œç´¢é–¢æ•°
    tavily_search, tavily_collect_context, context_to_bullets,
    # ãƒ†ã‚¹ãƒˆãƒ„ãƒ¼ãƒ«
    generate_slidev_test,
)

# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å›ºæœ‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from typing_extensions import TypedDict
from typing import Optional, Dict, Any, Union, List
from langsmith import traceable
from langgraph.graph import StateGraph, START, END
from langchain_core.runnables import RunnableConfig
import os
import re
import json
import shutil
import subprocess
from datetime import datetime, timedelta, timezone
from pathlib import Path


# -------------------
# State
# -------------------
class State(TypedDict):
  """LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®çŠ¶æ…‹ç®¡ç†"""

  # å…¥åŠ›
  topic: str                                    # ã‚¹ãƒ©ã‚¤ãƒ‰ã®ä¸»é¡Œ

  # æƒ…å ±åé›† (Node A)
  sources: Dict[str, List[Dict[str, str]]]      # Tavilyæ¤œç´¢çµæœ
  context_md: str                               # æ¤œç´¢çµæœã®Markdown

  # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ (Node B-D)
  key_points: List[str]                         # é‡è¦ãƒã‚¤ãƒ³ãƒˆ5å€‹
  toc: List[str]                                # ç›®æ¬¡5-8é …ç›®
  slide_md: str                                 # Marpã‚¹ãƒ©ã‚¤ãƒ‰æœ¬æ–‡
  title: str                                    # ã‚¹ãƒ©ã‚¤ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«

  # è©•ä¾¡ (Node E)
  score: float                                  # ç·åˆã‚¹ã‚³ã‚¢ (0-10)
  subscores: Dict[str, float]                   # é …ç›®åˆ¥ã‚¹ã‚³ã‚¢
  reasons: Dict[str, str]                       # è©•ä¾¡ç†ç”±
  suggestions: List[str]                        # æ”¹å–„ææ¡ˆ
  risk_flags: List[str]                         # ãƒªã‚¹ã‚¯äº‹é …
  passed: bool                                  # åˆæ ¼åˆ¤å®š (>=8.0)
  feedback: str                                 # ç·åˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
  attempts: int                                 # ãƒªãƒˆãƒ©ã‚¤å›æ•° (æœ€å¤§3)

  # å‡ºåŠ› (Node F)
  slide_path: str                               # ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

  # ã‚·ã‚¹ãƒ†ãƒ 
  error: str                                    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
  log: List[str]                                # å®Ÿè¡Œãƒ­ã‚°

# =======================
# å…¥åŠ›ã‚¿ã‚¤ãƒ—è‡ªå‹•åˆ¤åˆ¥ (Issue #17)
# =======================
def detect_input_type(topic: str) -> str:
    """
    å…¥åŠ›ã‚¿ã‚¤ãƒ—ã‚’è‡ªå‹•åˆ¤åˆ¥
    Returns: "pdf" | "youtube" | "text"
    """
    topic_lower = topic.lower()

    # YouTube URLãƒ‘ã‚¿ãƒ¼ãƒ³
    youtube_patterns = [
        r'youtube\.com/watch\?v=',
        r'youtu\.be/',
        r'youtube\.com/embed/',
    ]
    for pattern in youtube_patterns:
        if re.search(pattern, topic_lower):
            return "youtube"

    # PDFãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
    if topic_lower.endswith('.pdf') or '/uploads/' in topic_lower:
        return "pdf"

    # ãã‚Œä»¥å¤–ã¯ãƒ†ã‚­ã‚¹ãƒˆï¼ˆTavilyæ¤œç´¢ï¼‰
    return "text"

# =======================
# Node A: æƒ…å ±åé›†ï¼ˆPDF/YouTube/Tavilyå¯¾å¿œï¼‰
# =======================
@traceable(run_name="a_collect_info")
def collect_info(state: State) -> State:
  topic = state.get("topic") or "AIæœ€æ–°æƒ…å ±"

  # å…¥åŠ›ã‚¿ã‚¤ãƒ—ã‚’è‡ªå‹•åˆ¤åˆ¥
  input_type = detect_input_type(topic)

  try:
    # PDFå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    if input_type == "pdf":
      # æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ§‹é€ å¯¾å¿œï¼‰
      try:
        from .tools.pdf_processor import process_pdf
      except ImportError:
        from tools.pdf_processor import process_pdf
      result = process_pdf(topic)
      data = json.loads(result)

      if data["status"] == "success":
        # PDFã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ•´å½¢
        pdf_filename = Path(topic).stem
        context_md = f"# PDF: {pdf_filename}\n\n{data['content'][:10000]}"  # æœ€åˆã®10000æ–‡å­—

        # sourcesã«ä¿å­˜ï¼ˆå¾Œã§å‚ç…§å¯èƒ½ã«ï¼‰
        sources = {
          "pdf_content": [{
            "title": pdf_filename,
            "url": topic,
            "content": data['content'][:500],  # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨
            "num_pages": data.get('num_pages', 0),
            "total_chars": data.get('total_chars', 0)
          }]
        }

        return {
          "sources": sources,
          "context_md": context_md,
          "log": _log(state, f"[pdf] pages={data.get('num_pages')}, chars={data.get('total_chars')}")
        }
      else:
        return {"error": f"PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {data['message']}", "log": _log(state, f"[pdf] ERROR {data['message']}")}

    # YouTubeå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆå°†æ¥å®Ÿè£…ï¼‰
    elif input_type == "youtube":
      return {"error": "YouTubeå‡¦ç†ã¯æº–å‚™ä¸­ã§ã™ï¼ˆIssue #18ã§å®Ÿè£…äºˆå®šï¼‰", "log": _log(state, "[youtube] NOT_IMPLEMENTED")}

    # ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ï¼ˆæ—¢å­˜ã®Tavilyæ¤œç´¢ï¼‰
    else:
      # JSTã®ç¾åœ¨æ—¥æ™‚ ã¨ã€€æœˆè‹±èªè¡¨è¨˜ã‚’å–å¾—
      def month_en_for(dt: datetime) -> str:
        months = ["January","February","March","April","May","June",
                  "July","August","September","October","November","December"]
        return f"{months[dt.month-1]} {dt.year}"

      now = now_jst()
      # å…ˆæœˆã¯ã€æœˆæœ«æ—¥ã®1æ—¥ã«ãªã‚‹
      prev_month_dt = now.replace(day=1) - timedelta(days=1)
      # ç›´è¿‘2ãƒ¶æœˆ
      month_labels = [month_en_for(now), month_en_for(prev_month_dt)]

      # ãƒ™ãƒ³ãƒ€ãƒ¼æ¯ã®å…¬å¼ãƒ‰ãƒ¡ã‚¤ãƒ³
      vendors_domains = [
            (["azure.microsoft.com","news.microsoft.com","learn.microsoft.com"],
             ["Microsoft AI updates", "Azure OpenAI updates"]),
            (["openai.com"], ["OpenAI announcements","OpenAI updates"]),
            (["blog.google","ai.googleblog.com","research.google"], ["Google AI updates", "Gemini updates"]),
            (["aws.amazon.com"], ["AWS Bedrock updates","Amazon AI updates"]),
            (["ai.meta.com"], ["Meta AI updates", "Llama updates"]),
            (["anthropic.com"], ["Anthropic Claude updates","Claude announcements"]),
        ]

      # â˜… ç›´è¿‘2ãƒ¶æœˆ Ã— å„ç¤¾ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ§‹æˆ
      queries: List[Dict[str, Any]] = []
      for m in month_labels:
        for domains, patterns in vendors_domains:
          for p in patterns:
            queries.append({"q": f"{p} {m}", "include_domains": domains, "time_range": "month"})

      sources = tavily_collect_context(queries, max_per_query=6, default_time_range="month")
      context_md = context_to_bullets(sources)
      return {
        "sources": sources,
        "context_md": context_md,
        "log": _log(state, f"[tavily] months={month_labels} queries={len(queries)}")
      }

  except Exception as e:
    return {"error": f"collect_info_error: {e}", "log": _log(state, f"[collect_info] EXCEPTION {e}")}

# -------------------
# Node B: é‡è¦ãƒã‚¤ãƒ³ãƒˆç”Ÿæˆ
# -------------------
@traceable(run_name="b_generate_key_points")
def generate_key_points(state: State) -> Dict:
  topic = state.get("topic") or "AIæœ€æ–°æƒ…å ±"
  ctx = state.get("context_md") or ""

  # å…¥åŠ›ã‚¿ã‚¤ãƒ—ã‚’åˆ¤åˆ¥
  input_type = detect_input_type(topic)

  # PDFå‡¦ç†ã®å ´åˆã¯æ±ç”¨çš„ãªãƒã‚¤ãƒ³ãƒˆæŠ½å‡º
  if input_type == "pdf":
    prompt = [
      ("system", "ã‚ãªãŸã¯æ•™è‚²ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚PDFã®å†…å®¹ã‹ã‚‰é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡ºã—ã¾ã™ã€‚"),
      ("user",
        f"ä»¥ä¸‹ã®PDFå†…å®¹ã‹ã‚‰ã€ä¸­å­¦ç”Ÿã«ã‚‚ã‚ã‹ã‚‹ã‚ˆã†ã«é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’5å€‹ã€"
        f"çŸ­ã„ç®‡æ¡æ›¸ãã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚\n\n"
        f"[PDFå†…å®¹]\n{ctx[:4000]}\n\n"  # æœ€å¤§4000æ–‡å­—
        f"ç®‡æ¡æ›¸ãå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:")
    ]
  else:
    # AIæœ€æ–°æƒ…å ±ã®å ´åˆã¯æ—¢å­˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt = [
      ("system", "ã‚ãªãŸã¯Solution Engineerã§ã™ã€‚ã“ã‚Œã‹ã‚‰Marpã‚¹ãƒ©ã‚¤ãƒ‰ã§AIæœ€æ–°æƒ…å ±ã‚’ç™ºè¡¨ã—ã¾ã™ã€‚"),
      ("user",
        "ä»¥ä¸‹ã®ã€Œæœ€æ–°æƒ…å ±ã‚µãƒãƒªï¼ˆå‡ºå…¸ä»˜ãï¼‰ã€ã‚’å‚è€ƒã«ã€ç™ºè¡¨ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’å„ç¤¾5å€‹ã€"
        "çŸ­ã„ç®‡æ¡æ›¸ãã§ã€‚URLã‚‚å«ã‚ã¦ãã ã•ã„ã€‚\n\n"
        f"[æœ€æ–°æƒ…å ±ã‚µãƒãƒª]\n{ctx}\n\n[ãƒˆãƒ”ãƒƒã‚¯]\n{topic}")
    ]

  try:
    msg = llm.invoke(prompt)
    bullets = _strip_bullets(msg.content.splitlines())[:5] or [msg.content.strip()]
    return {"key_points": bullets, "log": _log(state, f"[key_points] {bullets}")}
  except Exception as e:
    return {"error": f"key_points_error: {e}", "log": _log(state, f"[key_points] EXCEPTION {e}")}

# -------------------
# Node C: ç›®æ¬¡ç”Ÿæˆ
# -------------------
@traceable(run_name="c_generate_toc")
def generate_toc(state: State) -> Dict:
  topic = state.get("topic") or ""
  key_points = state.get("key_points") or []

  # å…¥åŠ›ã‚¿ã‚¤ãƒ—ã‚’åˆ¤åˆ¥
  input_type = detect_input_type(topic)

  # PDFå‡¦ç†ã®å ´åˆã¯ä¸­å­¦ç”Ÿå‘ã‘ã®ç« ç«‹ã¦
  if input_type == "pdf":
    prompt = [
      ("system", "ã‚ãªãŸã¯æ•™è‚²ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚ä¸­å­¦ç”Ÿå‘ã‘ã‚¹ãƒ©ã‚¤ãƒ‰ã®æ§‹æˆï¼ˆç›®æ¬¡ï¼‰ã‚’ä½œã‚Šã¾ã™ã€‚"),
      ("user",
       "ä»¥ä¸‹ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã€ä¸­å­¦ç”Ÿã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„5ã€œ8å€‹ã®ç« ç«‹ã¦ã‚’ JSON ã® {\"toc\": [ ... ]} å½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚\n\n"
       "é‡è¦ãƒã‚¤ãƒ³ãƒˆ:\n- " + "\n- ".join(key_points) + "\n\n"
       "ç« ç«‹ã¦ã¯ã‚·ãƒ³ãƒ—ãƒ«ã§è¦ªã—ã¿ã‚„ã™ã„è¨€è‘‰ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚")
    ]
  else:
    # AIæœ€æ–°æƒ…å ±ã®å ´åˆã¯æ—¢å­˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt = [
      ("system", "ã‚ãªãŸã¯Solution Engineerã§ã™ã€‚Marpã‚¹ãƒ©ã‚¤ãƒ‰ã®æ§‹æˆï¼ˆç›®æ¬¡ï¼‰ã‚’ä½œã‚Šã¾ã™ã€‚"),
      ("user",
       "ä»¥ä¸‹ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã€5ã€œ8å€‹ã®ç« ç«‹ã¦ï¼ˆé…åˆ—ï¼‰ã‚’ JSON ã® {\"toc\": [ ... ]} å½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚\n\n"
       "é‡è¦ãƒã‚¤ãƒ³ãƒˆ:\n- " + "\n- ".join(key_points))
    ]

  try:
    msg = llm.invoke(prompt)
    try:
      data = json.loads(_find_json(msg.content) or msg.content)
      toc = [s.strip() for s in data.get("toc", []) if s.strip()]
    except Exception as e:
      toc = _strip_bullets(msg.content.splitlines())
      toc = toc[:8] or ["ã¯ã˜ã‚ã«", "èƒŒæ™¯", "å®Ÿè£…æ‰‹é †", "è©•ä¾¡ã¨æ”¹å–„", "å…¬é–‹ãƒ»é‹ç”¨", "ã¾ã¨ã‚"]
    return {"toc": toc, "error": "", "log": _log(state, f"[toc] {toc}")}
  except Exception as e:
    return {"error": f"toc_error: {e}", "log": _log(state, f"[toc] EXCEPTION {e}")}

# -------------------
# Node D: ã‚¹ãƒ©ã‚¤ãƒ‰æœ¬æ–‡ï¼ˆSlidevï¼‰ç”Ÿæˆ (Phase 1 - MVP-1)
# -------------------
@traceable(run_name="d_generate_slide_slidev")
def write_slides_slidev(state: State) -> Dict:
  """Slidevå½¢å¼ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”Ÿæˆï¼ˆå…¨6ç¤¾å¯¾å¿œ / PDFå¯¾å¿œï¼‰"""
  sources = state.get("sources") or {}
  topic = state.get("topic") or "AIæœ€æ–°æƒ…å ±"
  context_md = state.get("context_md") or ""
  key_points = state.get("key_points") or []
  toc = state.get("toc") or []

  # å…¥åŠ›ã‚¿ã‚¤ãƒ—ã‚’åˆ¤åˆ¥
  input_type = detect_input_type(topic)

  try:
    # PDFå‡¦ç†ã®å ´åˆã¯æ±ç”¨çš„ãªã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”Ÿæˆ
    if input_type == "pdf":
      # PDFãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
      pdf_filename = Path(topic).stem if topic.endswith('.pdf') else "PDFè³‡æ–™"
      ja_title = f"{pdf_filename} - ä¸­å­¦ç”Ÿå‘ã‘è§£èª¬"

      # LLMã§Slidevãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’ç”Ÿæˆ
      prompt = [
        ("system",
         "ã‚ãªãŸã¯æ•™è‚²ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚PDFã®å†…å®¹ã‚’ä¸­å­¦ç”Ÿã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã™ã‚‹Slidevã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä½œæˆã—ã¾ã™ã€‚"),
        ("user",
         f"ä»¥ä¸‹ã®PDFå†…å®¹ã‹ã‚‰ã€ä¸­å­¦ç”Ÿå‘ã‘ã®ã‚ã‹ã‚Šã‚„ã™ã„ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"
         f"ã€PDFå†…å®¹ã€‘\n{context_md[:8000]}\n\n"  # æœ€å¤§8000æ–‡å­—
         f"ã€é‡è¦ãƒã‚¤ãƒ³ãƒˆã€‘\n" + "\n".join([f"- {kp}" for kp in key_points[:5]]) + "\n\n"
         f"ã€ç›®æ¬¡ã€‘\n" + "\n".join([f"- {t}" for t in toc[:8]]) + "\n\n"
         f"ã€è¦ä»¶ã€‘\n"
         f"- Slidevå½¢å¼ï¼ˆYAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ + Markdownï¼‰\n"
         f"- theme: apple-basic ã‚’ä½¿ç”¨\n"
         f"- ã‚¿ã‚¤ãƒˆãƒ«ã‚¹ãƒ©ã‚¤ãƒ‰: # {ja_title}\n"
         f"- Agendaã‚¹ãƒ©ã‚¤ãƒ‰: ç›®æ¬¡ã‚’<v-clicks>ã§è¡¨ç¤º\n"
         f"- å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³: ç›®æ¬¡ã«åŸºã¥ã„ã¦5-8ã‚¹ãƒ©ã‚¤ãƒ‰ä½œæˆ\n"
         f"- å„ã‚¹ãƒ©ã‚¤ãƒ‰ã¯ç°¡æ½”ã«ï¼ˆ1ã‚¹ãƒ©ã‚¤ãƒ‰1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰\n"
         f"- ä¸­å­¦ç”Ÿã§ã‚‚ã‚ã‹ã‚‹è¨€è‘‰ã§èª¬æ˜\n"
         f"- çµµæ–‡å­—ã‚’æ´»ç”¨ã—ã¦è¦–è¦šçš„ã«\n"
         f"- ã¾ã¨ã‚ã‚¹ãƒ©ã‚¤ãƒ‰: é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’3-5å€‹ã«å‡ç¸®\n\n"
         f"å‡ºåŠ›ã¯Slidevãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã¿ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ä¸è¦ï¼‰:")
      ]

      msg = llm.invoke(prompt)
      slide_md = msg.content.strip()

      # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚Œã°é™¤å»
      slide_md = _strip_whole_code_fence(slide_md)

      return {
        "slide_md": slide_md,
        "title": ja_title,
        "error": "",
        "log": _log(state, f"[slides_slidev_pdf] generated ({len(slide_md)} chars) from PDF")
      }

    # AIæœ€æ–°æƒ…å ±ï¼ˆTavilyï¼‰ã®å ´åˆã¯æ—¢å­˜ã®ãƒãƒ«ãƒãƒ™ãƒ³ãƒ€ãƒ¼ç”Ÿæˆ
    else:
      ja_title = f"{month_ja()} AIæœ€æ–°æƒ…å ±ã¾ã¨ã‚"
      slide_md = _generate_multi_vendor_slides_integrated(
        topic=ja_title,
        sources=sources,
        mvp_version="AI Industry Report 2025"
      )

      return {
        "slide_md": slide_md,
        "title": ja_title,
        "error": "",
        "log": _log(state, f"[slides_slidev] generated ({len(slide_md)} chars, 6 vendors)")
      }

  except Exception as e:
    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”Ÿæˆ
    fallback_md = f"""---
theme: apple-basic
highlighter: shiki
class: text-center
---

# ğŸš€ {ja_title}
## ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ

<div class="pt-12">
  <span class="px-2 py-1 rounded" style="background: #ef4444; color: white;">
    Error: {str(e)}
  </span>
</div>

---

## âš ï¸ ã‚¨ãƒ©ãƒ¼è©³ç´°

ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

- æ¤œç´¢çµæœã®å–å¾—ã«å¤±æ•—ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
- ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„

"""
    return {
      "slide_md": fallback_md,
      "title": ja_title,
      "error": f"slides_slidev_error: {e}",
      "log": _log(state, f"[slides_slidev] EXCEPTION {e} - using fallback")
    }

# -------------------
# Node E: è©•ä¾¡ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰å‰æï¼‰
# -------------------
MAX_ATTEMPTS = 3

# Slidevç”¨è©•ä¾¡ãƒãƒ¼ãƒ‰ (Phase 3)
@traceable(run_name="e_evaluate_slides_slidev")
def evaluate_slides_slidev(state: State) -> Dict:
  """Slidevã‚¹ãƒ©ã‚¤ãƒ‰ã®å“è³ªè©•ä¾¡"""
  if state.get("error"):
    return {}
  slide_md = state.get("slide_md") or ""
  toc = state.get("toc") or []
  topic = state.get("topic") or ""
  eval_guide = (
        "è©•ä¾¡è¦³ç‚¹ã¨é‡ã¿:\n"
        "- structure(0.20): ã‚¹ãƒ©ã‚¤ãƒ‰ã®æµã‚Œã€ç« ç«‹ã¦ã€1ã‚¹ãƒ©ã‚¤ãƒ‰1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n"
        "- practicality(0.25): å®Ÿå‹™ã«ä½¿ãˆã‚‹å…·ä½“æ€§ï¼ˆæ‰‹é †ã€å…·ä½“ä¾‹ã€æ³¨æ„ç‚¹ï¼‰\n"
        "- accuracy(0.25): äº‹å®Ÿãƒ»ç”¨èªã®æ­£ç¢ºã•\n"
        "- readability(0.15): ç°¡æ½”æ˜ç­ã€è¦–èªæ€§ï¼ˆç®‡æ¡æ›¸ãã®ç²’åº¦ï¼‰\n"
        "- conciseness(0.15): å†—é•·æ€§ã®å°‘ãªã•\n"
        "åˆæ ¼: score >= 8.0\n"
  )
  prompt = [
        ("system",
         "ã‚ãªãŸã¯Cloud Solution Architectã§ã™ã€‚ä»¥ä¸‹ã®Slidevã‚¹ãƒ©ã‚¤ãƒ‰Markdownã‚’ã€"
         "æŒ‡å®šã®è¦³ç‚¹ãƒ»é‡ã¿ã§å³å¯†ã«æ¡ç‚¹ã—ã¾ã™ã€‚å‡ºåŠ›ã¯JSONã®ã¿ã€‚"),
        ("user",
         f"Topic: {topic}\nTOC: {json.dumps(toc, ensure_ascii=False)}\n\n"
         "Slides (Slidev Markdown):\n<<<SLIDES\n" + slide_md + "\nSLIDES\n\n"
         "Evaluation Guide:\n<<<EVAL\n" + eval_guide + "\nEVAL\n\n"
         "Return strictly this JSON schema:\n"
         "{\n"
         "  \"score\": number,\n"
         "  \"subscores\": {\"structure\": number, \"practicality\": number, \"accuracy\": number, \"readability\": number, \"conciseness\": number},\n"
         "  \"reasons\": {\"structure\": string, \"practicality\": string, \"accuracy\": string, \"readability\": string, \"conciseness\": string},\n"
         "  \"suggestions\": [string],\n"
         "  \"risk_flags\": [string],\n"
         "  \"pass\": boolean,\n"
         "  \"feedback\": string\n"
         "}"
        )]
  try:
    msg = llm.invoke(prompt)
    raw = msg.content or ""
    js = _find_json(raw) or raw
    data = json.loads(js)

    score = float(data.get("score", 0.0))
    subscores = data.get("subscores") or {}
    reasons = data.get("reasons") or {}
    suggestions = data.get("suggestions") or []
    risk_flags = data.get("risk_flags") or []
    passed = bool(data.get("pass", score >= 8.0))
    feedback = str(data.get("feedback", "")).strip()
    attempts = (state.get("attempts") or 0) + 1

    return {
      "score": score,
      "subscores": subscores,
      "reasons": reasons,
      "suggestions": suggestions,
      "risk_flags": risk_flags,
      "passed": passed,
      "feedback": feedback,
      "attempts": attempts,
      "log": _log(state, f"[evaluate_slidev] score={score:.2f} pass={passed} attempts={attempts}")
    }
  except Exception as e:
    return {"error": f"eval_error: {e}", "log": _log(state, f"[evaluate_slidev] EXCEPTION {e}")}

def route_after_eval_slidev(state: State) -> str:
    """è©•ä¾¡çµæœã«åŸºã¥ã„ã¦ãƒªãƒˆãƒ©ã‚¤ã¾ãŸã¯å®Œäº†ã‚’åˆ¤å®š"""
    if (state.get("attempts") or 0) >= MAX_ATTEMPTS:
        return "ok"
    return "ok" if state.get("passed") else "retry"

# -------------------
# Node F: ä¿å­˜ & Slidevãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° (Phase 1 - MVP-2)
# -------------------
@traceable(run_name="f_save_and_render_slidev")
def save_and_render_slidev(state: State) -> Dict:
  """Slidevå½¢å¼ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä¿å­˜ã—ã¦PDFç”Ÿæˆ"""
  if state.get("error"):
    return {}

  slide_md = state.get("slide_md") or ""
  title = state.get("title") or "AIã‚¹ãƒ©ã‚¤ãƒ‰"

  # ã‚¹ãƒ©ã‚¤ãƒ‰å†…å®¹ãŒç©ºã®å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
  if not slide_md.strip():
    return {
      "error": "slide_md is empty",
      "log": _log(state, "[save_slidev] ERROR: slide_md is empty")
    }

  # ã‚¹ãƒ©ã‚¤ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«åã®è‹±èªè¡¨è¨˜ã‚’ç”Ÿæˆ
  slug_prompt = [
    ("system", "You create concise English slugs for filenames."),
    ("user",
     "Convert the following Japanese title into a short English filename base (<=6 words). "
     "Only letters and spaces; no punctuation or numbers.\n\n"
     f"Title: {title}")
  ]

  try:
    emsg = llm.invoke(slug_prompt)
    file_stem = _slugify_en(emsg.content.strip()) or _slugify_en(title)
  except Exception:
    file_stem = _slugify_en(title) or "ai-latest-info"

  slide_dir = Path(__file__).parent / "slides"
  slide_dir.mkdir(parents=True, exist_ok=True)
  slide_md_path = slide_dir / f"{file_stem}_slidev.md"
  slide_md_path.write_text(slide_md, encoding="utf-8")

  # Slidev PDFç”Ÿæˆ
  slidev = shutil.which("slidev")
  out_path = str(slide_md_path)

  if slidev and SLIDE_FORMAT == "pdf":
    pdf_file = slide_dir / f"{file_stem}_slidev.pdf"
    try:
      subprocess.run(
        ["slidev", "export", str(slide_md_path),
         "--output", str(pdf_file),
         "--format", "pdf",
         "--timeout", "60000"],  # 60ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        check=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        timeout=90  # ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
      )
      out_path = str(pdf_file)
      log_msg = f"[slidev] generated PDF -> {pdf_file.name}"
    except subprocess.TimeoutExpired:
      log_msg = f"[slidev] PDF generation timeout (90s) - MD saved at {slide_md_path.name}"
    except subprocess.CalledProcessError as e:
      error_msg = e.stderr.decode() if e.stderr else str(e)
      log_msg = f"[slidev] export failed: {error_msg[:100]} - MD saved"
  else:
    if not slidev:
      log_msg = "[slidev] slidev-cli not found â€“ skipped rendering (left .md)."
    else:
      log_msg = f"[slidev] rendering skipped (SLIDE_FORMAT={SLIDE_FORMAT}, only pdf supported)."

  return {
    "slide_path": out_path,
    "log": _log(state, log_msg)
  }

# -------------------
# ã‚°ãƒ©ãƒ•æ§‹ç¯‰
# -------------------
graph_builder = StateGraph(State)
graph_builder.add_node("collect_info", collect_info)
graph_builder.add_node("generate_key_points", generate_key_points)
graph_builder.add_node("generate_toc", generate_toc)
graph_builder.add_node("write_slides_slidev", write_slides_slidev)
graph_builder.add_node("save_and_render_slidev", save_and_render_slidev)
graph_builder.add_node("evaluate_slides_slidev", evaluate_slides_slidev)

# ã‚¨ãƒƒã‚¸å®šç¾©ï¼ˆSlidevãƒ•ãƒ­ãƒ¼ with è©•ä¾¡ãƒ«ãƒ¼ãƒ—ï¼‰
graph_builder.add_edge(START, "collect_info")
graph_builder.add_edge("collect_info", "generate_key_points")
graph_builder.add_edge("generate_key_points", "generate_toc")
graph_builder.add_edge("generate_toc", "write_slides_slidev")
graph_builder.add_edge("write_slides_slidev", "evaluate_slides_slidev")

# è©•ä¾¡ãƒ«ãƒ¼ãƒ—ï¼ˆæœ€å¤§3å›ãƒªãƒˆãƒ©ã‚¤ï¼‰
graph_builder.add_conditional_edges(
  "evaluate_slides_slidev",
  route_after_eval_slidev,
  {"retry": "generate_key_points", "ok": "save_and_render_slidev"}
)

graph_builder.add_edge("save_and_render_slidev", END)

graph = graph_builder.compile()

# -------------------
# å®Ÿè¡Œ
# -------------------
if __name__ == "__main__":
  print("LangSmith Tracing:", os.getenv("LANGCHAIN_TRACING_V2"),
      "| Project:", os.getenv("LANGCHAIN_PROJECT"))
  init: State = {
    "topic": "LangGraph Ã— LangSmith Ã— OpenAI Ã— Tavilyã§ä½œã‚‹ï¼šæœ€æ–°AIå‹•å‘ã‚¹ãƒ©ã‚¤ãƒ‰",
    "key_points": [], "toc": [], "slide_md": "",
    "score": 0.0,
    "subscores": {}, "reasons": {},
    "suggestions": [], "risk_flags": [],
    "passed": False, "feedback": "",
    "title": "", "slide_path": "",
    "attempts": 0, "error": "", "log": [],
    "context_md": "", "sources": {}
  }

  config: RunnableConfig = {
    "run_name": "tavily_marp_agent",
    "tags": ["marp", "langgraph", "langsmith", "openai", "tavily"],
    "metadata": {"env": "dev", "date": datetime.now(timezone.utc).isoformat()},
    "recursive_limit": 60,
  }
  out = graph.invoke(init, config=config)

  print("\n=== RESULT ===")
  if out.get("error"):
    print("ERROR:", out["error"])
  else:
    print("Title    :", out.get("title"))
    print("Slide    :", out.get("slide_path"))
    # print("Score    :", out.get("score"))
    # print("Passed   :", out.get("passed"))
  print("\n=== LOGS ===")
  for line in out.get("log", []):
    print(line)